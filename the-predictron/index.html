<html>
  <meta charset="utf8">
  <head>
    <title>
      抄訳 THE PREDICTRON
    </title>
  </head>
  <body>
    <h2>抄訳 THE PREDICTRON</h2>
    <a href="https://arxiv.org/abs/1612.08810">元論文</a>
    <h3>ABSTRACT</h3>
      <p> 
        planningの文脈で効率的な燃えるを学習することは，AIの主な挑戦の一つである．
        ここでは，<i>predictron</i>というアーキテクチャを紹介する．
        predictronは報酬付きマルコフ過程で表される，完全に抽象的なモデルを用いている．
        この報酬付きマルコフ過程は多数の仮想的なplanningステップをシミュレートすることができる．
        <b>predictronは，すべてのシミュレーション結果について，その内部的な報酬と価値を加算する．</b>
        predictronは，その値が本来の価値関数に正しく近似するように，端から端まで学習する．
        この論文では，predictronを，手続き的に生成されたランダムな迷路，そしてビリヤードゲームシミュレータに適応した．
        predictronは従来のdeep nural networkよりも高い精度を生んだ．
      </p>
    <h3>INTRODUCTION</h3>
      <p>
        モデルに基づいた強化学習の中心的なアイデアは，二つの部分問題に分けるということである．
        すなわち，まず環境のモデルを学習し，次にその学習したモデルを用いてplanningする，という二つの問題である．
        モデルは，典型的には報酬付きマルコフ過程か，マルコフ決定過程を用いて表現される．
        planningはそのモデルを，評価と，最適戦略の選択に用いる．
        これは典型的には，モデルをシミュレーションし累積報酬を予想する価値関数を構成することで達成される．
        以前までは，このモデルはplannerの中で，その使用に独立して学習することが必要であった．
        結果として，そのモデルはエージェントの目的に全体的には，良く適合するものは得られなかった．
        以前の深層強化学習の手法はほぼpixel-perfect reconstructionsに展開できるモデルを構成することに成功したが，
        生入力を用いての強化学習の最先端のmodel-free手法をまだ超えていなかった．
      </p>

      <p>
        ここでは，<i>predictron</i>という，学習とplanningをあわせて，端から端までの学習手順に統合したアーキテクチャを紹介する．
        全てのステップで，モデルはある内部的な状態に適用され，次の状態，報酬，割引，そして価値予想を得る．このモデルは完全に抽象的であり，その目的はただ正確な価値予想を容易にすることである．
        例えば，ゲームで効率的にplanするためには，エージェントはスコアを予想する必要がある．もしこのモデルが正確な予想をするなら，このモデルに関して，理想的なplanは，根本的なゲームに対する理想的なplanにもなっていて，それは例え
        モデルが異なる状態空間，行動空間，報酬を用いていたり，さらには時間が異なっていてもである（一つの時間のステップで，エージェントを廊下の最後に"jump"させることができる）．
        ここで必要なことは，ただ，抽象的なモデルを通しての軌跡が，実際の環境の軌道と一致するような評価を生むことである．
        このことは，できるだけ正確に正しく評価するために，端から端までの予想を学習することで達成される．
      </p>

      <p>
        一つの理想的なモデルは，一つの予測課題に対して過度に適合するよりは，多くの異なる予想課題に対して一般化できるものであり，そして，非本質的な報酬のみを学習するのではなく，豊富な種類のフィードバックを学習できることである．
        それゆえ，predictronを，様々な疑似報酬関数と，割引要因に対して，数多くの異なる価値関数を予測するように学習する．それらの疑似報酬関数はエージェントが注意すべき環境の側面やイベントをエンコードすることができる．
      </p>

      <p>
        ここでは，予測課題について注目する，すなわち制御なしの遷移の報酬付きマルコフ過程環境下で価値関数を推測することである．この場合には，predictronはrecurrent coreとして報酬付きマルコフ過程とdeep neural networrkとして実装される．
        predictronはこの複数のステップの核を解き，全体的な価値の予想に対しての報酬の和をとる．
      </p>

      <p>
        ここではpredictronを手続き的に生成したランダムな迷路と，ビリヤードゲームシミュレータに対して，画素の入力データから直接的に適用した．迷路，ビリヤード両方について，predictronは，驚くほど，従来のdeep network アーキテクチャを超える性能を生んだ．
        そしてそれは，従来よりも，深さのようなアーキテクチャの選択に対してrobustであった．
      </p>
  </body>
  
</html>
